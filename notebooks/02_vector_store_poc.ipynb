{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a9d517",
   "metadata": {},
   "source": [
    "# Notebook: Vector Store Proof of Concept\n",
    "\n",
    "This notebook demonstrates why a vector store like ChromaDB was chosen. Beyond simple key-value storage, it allows for powerful **semantic similarity searches**.\n",
    "\n",
    "**Goal:**\n",
    "1.  Create a temporary, in-memory ChromaDB instance.\n",
    "2.  Add several related and unrelated tasks.\n",
    "3.  Perform a natural language query against the database.\n",
    "4.  Verify that the most semantically relevant tasks are returned.\n",
    "\n",
    "This capability is the foundation for future features like finding duplicate tasks or retrieving contextually related information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e875061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In-memory ChromaDB collection created.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import chromadb\n",
    "from src.models.task import Task\n",
    "\n",
    "# Use an in-memory instance for this POC to avoid creating files\n",
    "client = chromadb.Client()\n",
    "collection = client.get_or_create_collection(name=\"poc_tasks\")\n",
    "\n",
    "print(\"✅ In-memory ChromaDB collection created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84bde6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added 4 tasks to the collection.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create sample tasks, being explicit with optional fields to satisfy the linter.\n",
    "tasks = [\n",
    "    Task(title=\"Finalize the quarterly marketing report\", category=\"Work\", description=None, due_date=None),\n",
    "    Task(title=\"Prepare slides for the project presentation\", category=\"Work\", description=None, due_date=None),\n",
    "    Task(title=\"Schedule a dentist appointment\", category=\"Personal\", description=None, due_date=None),\n",
    "    Task(title=\"Review the Q3 financial report\", category=\"Work\", description=None, due_date=None),\n",
    "]\n",
    "\n",
    "# Add tasks to the collection\n",
    "for task in tasks:\n",
    "    # Step 1: Convert Pydantic model to a dictionary, excluding None values\n",
    "    metadata = task.model_dump(exclude_none=True)\n",
    "\n",
    "    # Step 2: Convert any datetime objects into ISO 8601 strings\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, datetime):\n",
    "            metadata[key] = value.isoformat()\n",
    "    \n",
    "    # Step 3: Add the fully compliant metadata to the collection\n",
    "    collection.add(\n",
    "        ids=[task.id],\n",
    "        documents=[task.title + \" \" + (task.description or \"\")],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "\n",
    "print(f\"✅ Added {len(tasks)} tasks to the collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4bd318",
   "metadata": {},
   "source": [
    "## Performing the Semantic Search\n",
    "Now, let's ask a question in natural language and see which tasks the vector store considers most relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23cee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added 4 tasks to the collection.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create sample tasks, being explicit with optional fields to satisfy the linter.\n",
    "tasks = [\n",
    "    Task(title=\"Finalize the quarterly marketing report\", category=\"Work\", description=None, due_date=None),\n",
    "    Task(title=\"Prepare slides for the project presentation\", category=\"Work\", description=None, due_date=None),\n",
    "    Task(title=\"Schedule a dentist appointment\", category=\"Personal\", description=None, due_date=None),\n",
    "    Task(title=\"Review the Q3 financial report\", category=\"Work\", description=None, due_date=None),\n",
    "]\n",
    "\n",
    "# Add tasks to the collection\n",
    "for task in tasks:\n",
    "    # Step 1: Convert Pydantic model to a dictionary, excluding None values\n",
    "    metadata = task.model_dump(exclude_none=True)\n",
    "\n",
    "    # Step 2: Convert any datetime objects into ISO 8601 strings\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, datetime):\n",
    "            metadata[key] = value.isoformat()\n",
    "    \n",
    "    # Step 3: Add the fully compliant metadata to the collection\n",
    "    collection.add(\n",
    "        ids=[task.id],\n",
    "        documents=[task.title + \" \" + (task.description or \"\")],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "\n",
    "print(f\"✅ Added {len(tasks)} tasks to the collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5532e273",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As seen above, the query correctly identified \"Finalize the quarterly marketing report\" and \"Review the Q3 financial report\" as the most relevant tasks, even though the words don't match exactly. It correctly ignored the irrelevant dentist appointment task.\n",
    "\n",
    "This proves the power of using a vector store for semantic understanding and is a strong foundation for more advanced agent capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cbe0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
